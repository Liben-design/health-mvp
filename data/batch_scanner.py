import asyncio
import json
import os
import sys
import pandas as pd

# ç¢ºä¿å¯ä»¥å¾å°ˆæ¡ˆæ ¹ç›®éŒ„åŒ¯å…¥æ¨¡çµ„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from data.agent_d2c_scanner import AgentD2CScanner

async def main():
    # è¨­å®šæª”æ¡ˆè·¯å¾‘
    input_json = "data/target_product_urls.json"
    output_csv = "data/d2c_full_database.csv"

    # 1. è®€å–ç›®æ¨™æ¸…å–®
    if not os.path.exists(input_json):
        print(f"âŒ æ‰¾ä¸åˆ°è¼¸å…¥æª”æ¡ˆ: {input_json}")
        return

    print(f"ğŸ“‚ è®€å–ç›®æ¨™æ¸…å–®: {input_json}")
    with open(input_json, "r", encoding="utf-8") as f:
        target_list = json.load(f)
    
    # å»ºç«‹ URL -> Brand çš„æ˜ å°„ï¼Œç”¨æ–¼è£œå…¨ AI å¯èƒ½æ¼æ‰çš„å“ç‰Œè³‡è¨Š
    url_map = {item['url']: item['brand'] for item in target_list}
    urls_to_scan = [item['url'] for item in target_list]
    
    total_urls = len(urls_to_scan)
    print(f"ğŸš€ æº–å‚™æƒæ {total_urls} å€‹ç”¢å“é€£çµ...")

    # 2. åˆå§‹åŒ–æƒæå™¨
    scanner = AgentD2CScanner()
    all_data = []
    
    # 3. æ‰¹æ¬¡åŸ·è¡Œ (é¿å…ä¸€æ¬¡æ€§è«‹æ±‚éå¤šå°è‡´è¢«å°é–æˆ–è¨˜æ†¶é«”ä¸è¶³)
    batch_size = 5
    for i in range(0, total_urls, batch_size):
        batch_urls = urls_to_scan[i : i + batch_size]
        current_batch_num = (i // batch_size) + 1
        total_batches = (total_urls + batch_size - 1) // batch_size
        
        print(f"\nğŸ“¦ [Batch {current_batch_num}/{total_batches}] è™•ç†ä¸­ ({len(batch_urls)} items)...")
        
        # å‘¼å« Agent é€²è¡Œæƒæ
        results = await scanner.scan_batch(batch_urls)
        
        # è³‡æ–™å¾Œè™•ç†ï¼šè£œå…¨å“ç‰Œè³‡è¨Š
        for res in results:
            if res.get('url') in url_map:
                known_brand = url_map[res['url']]
                # è‹¥ AI åˆ¤æ–·ç‚º Unknown æˆ–ç©ºï¼Œå‰‡ä½¿ç”¨ Sitemap çš„å“ç‰Œè³‡è¨Š
                if not res.get('brand') or res.get('brand') == "Unknown":
                    res['brand'] = known_brand
        
        all_data.extend(results)
        
        # 4. å³æ™‚å­˜æª” (æ¯æ‰¹æ¬¡å­˜ä¸€æ¬¡ï¼Œé˜²æ­¢ä¸­æ–·éºå¤±)
        save_to_csv(all_data, output_csv)
        
        # æ‰¹æ¬¡é–“ä¼‘æ¯ï¼Œé™ä½è¢«å°é–é¢¨éšª
        if i + batch_size < total_urls:
            print("â³ å†·å» 3 ç§’...")
            await asyncio.sleep(3)

    print(f"\nğŸ‰ æƒæå®Œæˆï¼å…± {len(all_data)} ç­†æœ‰æ•ˆè³‡æ–™å·²å„²å­˜è‡³ {output_csv}")

def save_to_csv(data, filepath):
    if not data: return
    df = pd.DataFrame(data)
    # ç¢ºä¿æ¬„ä½ç¬¦åˆ Unified Schema
    schema = ["source", "brand", "title", "price", "unit_price", "total_count", "url", "image_url", "product_highlights"]
    for col in schema:
        if col not in df.columns: df[col] = ""
    df = df[schema]
    df.to_csv(filepath, index=False, encoding="utf-8-sig")
    print(f"ğŸ’¾ å·²æ›´æ–°å­˜æª”: {len(df)} ç­†")

if __name__ == "__main__":
    asyncio.run(main())