import asyncio
import random
import pandas as pd
import os
from datetime import datetime
from playwright.async_api import async_playwright

# å˜—è©¦åŒ¯å…¥ playwright_stealthï¼Œè‹¥ç„¡å‰‡æé†’å®‰è£
try:
    from playwright_stealth import stealth_async
except ImportError:
    print("Error: 'playwright-stealth' module not found. Please install it using: pip install playwright-stealth")
    exit(1)

# ==========================================
# è¨­å®šèˆ‡å¸¸æ•¸
# ==========================================
TARGET_URL = "https://shop.vitabox.com.tw/categories/featured-products"  # Vitabox ç”¢å“åˆ—è¡¨é 
OUTPUT_FILE = "data/d2c_vitabox.csv"
USER_AGENTS = [
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.2 Safari/605.1.15",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/121.0"
]

class VitaboxStealthCrawler:
    def __init__(self):
        self.data = []

    async def human_like_delay(self, min_seconds=2, max_seconds=5):
        """æ¨¡æ“¬äººé¡éš¨æ©Ÿæ€è€ƒ/é–±è®€æ™‚é–“"""
        delay = random.uniform(min_seconds, max_seconds)
        await asyncio.sleep(delay)

    async def random_mouse_move(self, page):
        """
        æ¨¡æ“¬äººé¡æ»‘é¼ éš¨æ©Ÿç§»å‹•
        ç¹ééƒ¨åˆ†åŸºæ–¼æ»‘é¼ è»Œè·¡çš„ Bot Detection
        """
        width = 1920
        height = 1080
        # éš¨æ©Ÿç”Ÿæˆ 3-5 å€‹ç§»å‹•é»
        for _ in range(random.randint(3, 5)):
            x = random.randint(100, width - 100)
            y = random.randint(100, height - 100)
            # steps è®“ç§»å‹•æœ‰è»Œè·¡æ„Ÿï¼Œä¸æ˜¯ç¬é–“è·³èº
            await page.mouse.move(x, y, steps=random.randint(10, 25))
            await asyncio.sleep(random.uniform(0.1, 0.3))

    async def progressive_scroll(self, page):
        """
        æ¼¸é€²å¼æ»¾å‹• (Progressive Scrolling)
        ç¢ºä¿ Lazy Load åœ–ç‰‡è¢«è§¸ç™¼ï¼Œä¸¦æ¨¡æ“¬äººé¡é–±è®€è¡Œç‚º
        (åƒ…è² è²¬æ»¾å‹•ç•¶å‰é é¢ï¼Œåˆ†é é‚è¼¯ç§»è‡³ run æ–¹æ³•è™•ç†)
        """
        print("ğŸ–±ï¸ é–‹å§‹æ¼¸é€²å¼æ»¾å‹•è¼‰å…¥é é¢...")
        
        last_height = await page.evaluate("document.body.scrollHeight")
        
        while True:
            # éš¨æ©Ÿæ»¾å‹•è·é›¢ (æ¨¡æ“¬æ»¾è¼ªæˆ– PageDown)
            scroll_amount = random.randint(400, 800)
            await page.mouse.wheel(0, scroll_amount)
            
            # æ»¾å‹•å¾Œéš¨æ©Ÿåœé “ï¼Œæ¨¡æ“¬é–±è®€
            await self.human_like_delay(1.5, 3.0)
            
            # å¶çˆ¾å¾€å›æ»¾ä¸€é»é»ï¼Œå¢åŠ çœŸå¯¦æ„Ÿ
            if random.random() < 0.3:
                await page.mouse.wheel(0, -random.randint(50, 150))
                await asyncio.sleep(random.uniform(0.5, 1.0))

            # æª¢æŸ¥æ˜¯å¦åˆ°åº•
            new_height = await page.evaluate("document.body.scrollHeight")
            current_scroll = await page.evaluate("window.scrollY + window.innerHeight")
            
            # å¦‚æœç›®å‰çš„è¦–çª—åº•éƒ¨å·²ç¶“æ¥è¿‘é é¢ç¸½é«˜åº¦ï¼Œå‰‡åœæ­¢
            if current_scroll >= new_height - 200:
                print("âœ… å·²æ»¾å‹•è‡³é é¢åº•éƒ¨ (æˆ–å·²ç„¡æ›´å¤šé é¢)")
                break
                
            # å¦‚æœé«˜åº¦æ²’æœ‰è®ŠåŒ–æŒçºŒå¤ªä¹…(å¯é¸é‚è¼¯)ï¼Œé€™è£¡ç°¡åŒ–ç‚ºä¾è³´ current_scroll
            last_height = new_height

    async def extract_product_data(self, page):
        """
        è§£æç”¢å“å¡ç‰‡è³‡æ–™
        ä½¿ç”¨è¼ƒç‚ºå¯¬é¬†çš„ Selector ç­–ç•¥ä»¥é©æ‡‰æ”¹ç‰ˆ
        """
        print("ğŸ” é–‹å§‹è§£æç”¢å“è³‡æ–™...")
        
        # å®šä½ç”¢å“å¡ç‰‡ï¼šé€šå¸¸åœ¨ Collection é é¢æœƒæœ‰ç‰¹å®šçš„ Grid Item Class
        # é€™è£¡å˜—è©¦æŠ“å–å¸¸è¦‹çš„ Shopify/Cyberbiz çµæ§‹
        # ç­–ç•¥ï¼šå°‹æ‰¾åŒ…å« 'product' ä¸”æœ‰ 'item' æˆ– 'card' çš„å®¹å™¨ï¼Œæˆ–æ˜¯ç›´æ¥æ‰¾é€£çµ
        # product_cards = await page.locator(".product-item, .product-card, .grid__item").all()
        
        # Shopline ç­–ç•¥ï¼šç›´æ¥æŠ“å–æ‰€æœ‰æŒ‡å‘ /products/ çš„ <a> æ¨™ç±¤
        # Shopline çš„ç”¢å“é€£çµé€šå¸¸æ˜¯ /products/product-slug
        product_cards = await page.locator("a[href*='/products/'], a[href*='/product/']").all()
        
        if not product_cards:
            print("âš ï¸ æœªåµæ¸¬åˆ°ä»»ä½•ç”¢å“é€£çµï¼Œå˜—è©¦ç­‰å¾…æ›´ä¹…...")
            # Fallback: æŠ“å–æ‰€æœ‰åŒ…å«åƒ¹æ ¼çš„é€£çµå€å¡Š
            product_cards = await page.locator("a[href*='/products/'], a[href*='/product/']").all()

        print(f"ğŸ“Š åµæ¸¬åˆ° {len(product_cards)} å€‹æ½›åœ¨ç”¢å“é …ç›®")

        for card in product_cards:
            try:
                # 1. Title
                title_el = card.locator("h3, h4, .title, .product-title").first
                # å¦‚æœæ‰¾ä¸åˆ°æ¨™é¡Œå…ƒç´ ï¼Œå˜—è©¦ç›´æ¥è®€å–é€£çµå…§çš„æ–‡å­—
                if await title_el.count() > 0:
                    title = await title_el.text_content()
                else:
                    title = await card.text_content()
                
                title = title.strip()
                # éæ¿¾æ‰å¤ªçŸ­çš„æ¨™é¡Œ (å¯èƒ½æ˜¯ "æŸ¥çœ‹æ›´å¤š" ä¹‹é¡çš„æŒ‰éˆ•)
                if len(title) < 2: continue
                
                # éæ¿¾éä¿å¥é£Ÿå“ (ç›¤å­ã€æè¢‹ç­‰)
                if any(keyword in title for keyword in ["ç“·ç›¤", "ç¦®è¢‹", "æè¢‹", "è³¼ç‰©è¢‹"]):
                    continue

                # 2. Price
                # å„ªå…ˆæ‰¾ç‰¹åƒ¹ï¼Œè‹¥ç„¡å‰‡æ‰¾åŸåƒ¹
                price_el = card.locator(".price, .money, span:has-text('NT$')").first
                # å¦‚æœå¡ç‰‡å…§æ‰¾ä¸åˆ°åƒ¹æ ¼ï¼Œå˜—è©¦å¾€ä¸Šå±¤æ‰¾ (æœ‰æ™‚ a æ¨™ç±¤åªæ˜¯åœ–ç‰‡ï¼Œåƒ¹æ ¼åœ¨å…„å¼Ÿå…ƒç´ )
                if await price_el.count() == 0:
                    # å˜—è©¦æ‰¾çˆ¶å±¤å®¹å™¨
                    parent = card.locator("..")
                    price_el = parent.locator(".price, .money, span:has-text('NT$')").first

                price_text = await price_el.text_content() if await price_el.count() > 0 else ""
                # æ¸…æ´—åƒ¹æ ¼: å»é™¤ NT$, é€—è™Ÿ, ç©ºç™½
                price = int(''.join(filter(str.isdigit, price_text)) or 0)

                # 3. URL
                # å¦‚æœ card æœ¬èº«æ˜¯ <a> æ¨™ç±¤
                raw_url = await card.get_attribute("href")
                
                full_url = f"https://shop.vitabox.com.tw{raw_url}" if raw_url.startswith("/") else raw_url

                # 4. Image
                img_el = card.locator("img").first
                raw_img_url = await img_el.get_attribute("src") or await img_el.get_attribute("data-src") or ""
                if raw_img_url.startswith("//"):
                    image_url = f"https:{raw_img_url}"
                elif raw_img_url.startswith("http"):
                    image_url = raw_img_url
                else:
                    image_url = ""

                # å»é‡æª¢æŸ¥ï¼šé¿å…åŒä¸€å€‹ç”¢å“æŠ“åˆ°å…©æ¬¡ (åœ–ç‰‡é€£çµå’Œæ–‡å­—é€£çµ)
                if any(d['url'] == full_url for d in self.data):
                    continue

                # 5. Highlights (å˜—è©¦å¾å¡ç‰‡æ–‡å­—ä¸­æå–éæ¨™é¡Œ/åƒ¹æ ¼çš„æè¿°)
                text_content = await card.text_content()
                # ç°¡å–®éæ¿¾ï¼šæŠŠæ¨™é¡Œå’Œåƒ¹æ ¼æ‰£æ‰å‰©ä¸‹çš„å­—ä¸²ç•¶ä½œæ½›åœ¨äº®é» (é€™å¾ˆç²—ç•¥ï¼Œä½†ç¬¦åˆ"å˜—è©¦æŠ“å–")
                highlights = text_content.replace(title, "").replace(price_text, "").strip()
                highlights = highlights.replace("\n", ";").strip()[:50] # æˆªæ–·é¿å…éé•·

                item = {
                    "source": "Vitabox",
                    "brand": "Vitabox",
                    "title": title,
                    "price": price,
                    "unit_price": 0, # ä¾æŒ‡ç¤ºå¡« 0
                    "url": full_url,
                    "image_url": image_url,
                    "product_highlights": highlights,
                    "total_count": "" # æš«ç©º
                }
                self.data.append(item)
                # print(f"   Found: {title} | ${price}")

            except Exception as e:
                # å®¹éŒ¯ï¼šå–®ä¸€ç”¢å“è§£æå¤±æ•—ä¸ä¸­æ–·æ•´å€‹çˆ¬èŸ²
                continue

    async def run(self):
        async with async_playwright() as p:
            # éš¨æ©Ÿé¸å– User-Agent
            user_agent = random.choice(USER_AGENTS)
            
            # å•Ÿå‹•ç€è¦½å™¨ (Headless=True ä¹Ÿå¯ä»¥ï¼Œä½† False æ–¹ä¾¿é™¤éŒ¯ä¸”æœ‰æ™‚è¼ƒä¸æ˜“è¢«æ“‹)
            browser = await p.chromium.launch(headless=True) 
            context = await browser.new_context(
                user_agent=user_agent,
                viewport={"width": 1920, "height": 1080},
                locale="zh-TW"
            )
            
            page = await context.new_page()
            
            # æ‡‰ç”¨ Stealth æ’ä»¶
            await stealth_async(page)

            print(f"ğŸš€ å•Ÿå‹•éš±èº«çˆ¬èŸ²ï¼Œç›®æ¨™: {TARGET_URL}")
            try:
                # æ”¹ç”¨ networkidle ç¢ºä¿å‹•æ…‹å…§å®¹è¼‰å…¥å®Œæˆ
                await page.goto(TARGET_URL, wait_until="networkidle", timeout=60000)
            except Exception:
                print("âš ï¸ NetworkIdle è¶…æ™‚ï¼Œå˜—è©¦ç¹¼çºŒåŸ·è¡Œ...")
            
            print(f"ğŸ“„ ç•¶å‰é é¢æ¨™é¡Œ: {await page.title()}")

            # åŸ·è¡Œæ“¬äººè¡Œç‚º
            await self.random_mouse_move(page)
            
            while True:
                await self.human_like_delay(2, 4)
                await self.progressive_scroll(page)
                
                # å†æ¬¡éš¨æ©Ÿç§»å‹•æ»‘é¼ ç¢ºä¿å…ƒç´ ç©©å®š
                await self.random_mouse_move(page)
                
                # æå–ç•¶å‰é é¢è³‡æ–™
                await self.extract_product_data(page)

                # æª¢æŸ¥ä¸¦è™•ç†ä¸‹ä¸€é  (Shopline åˆ†é çµæ§‹)
                # å˜—è©¦å¤šç¨®é¸æ“‡å™¨ä»¥ç¢ºä¿èƒ½æŠ“åˆ°æŒ‰éˆ•
                next_selectors = [
                    "a[rel='next']",                      # æ¨™æº–èªç¾©
                    "li.next a",                          # å¸¸è¦‹ Bootstrap çµæ§‹
                    ".pagination .next a",                # å¦ä¸€ç¨®çµæ§‹
                    ".pagination-next a",                 # Shopline è®Šé«”
                    "a:has-text('ä¸‹ä¸€é ')",               # ä¸­æ–‡æ–‡å­—
                    "a:has-text('Next')",                 # è‹±æ–‡æ–‡å­—
                    "a:has(i.fa-angle-right)",            # FontAwesome åœ–ç¤º
                    "a:has(i.fa-chevron-right)"           # å¦ä¸€ç¨®åœ–ç¤º
                ]
                
                next_btn = None
                for selector in next_selectors:
                    btn = page.locator(selector).first
                    if await btn.count() > 0 and await btn.is_visible():
                        next_btn = btn
                        print(f"ğŸ” ç™¼ç¾ä¸‹ä¸€é æŒ‰éˆ• (Selector: {selector})")
                        break
                
                if next_btn:
                    print("ğŸ‘‰ é»æ“Šä¸‹ä¸€é ...")
                    # é»æ“Šä¸¦ç­‰å¾…é é¢å°èˆªå®Œæˆ
                    await next_btn.click()
                    await page.wait_for_load_state("networkidle", timeout=60000)
                else:
                    print("âœ… å·²ç„¡ä¸‹ä¸€é ï¼Œåœæ­¢çˆ¬å–")
                    break
            
            await browser.close()

    def save_csv(self):
        if not self.data:
            print("âŒ æœªæŠ“å–åˆ°ä»»ä½•è³‡æ–™ã€‚")
            return
            
        df = pd.DataFrame(self.data)
        
        # ç¢ºä¿ç›®éŒ„å­˜åœ¨
        os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True)
        
        df.to_csv(OUTPUT_FILE, index=False, encoding="utf-8-sig")
        print(f"ğŸ’¾ è³‡æ–™å·²å„²å­˜è‡³: {OUTPUT_FILE} (å…± {len(df)} ç­†)")

if __name__ == "__main__":
    crawler = VitaboxStealthCrawler()
    asyncio.run(crawler.run())
    crawler.save_csv()
