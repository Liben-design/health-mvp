import asyncio
import time
import os
from d2c_daiken_crawler import scrape_daiken_all_products
from d2c_dietician_crawler import scrape_dietician_all_products
from d2c_vitabox_crawler import VitaboxStealthCrawler

async def run_vitabox():
    """å°è£ Vitabox çˆ¬èŸ²åŸ·è¡Œé‚è¼¯"""
    print("ğŸš€ [Vitabox] ä»»å‹™å•Ÿå‹•...")
    crawler = VitaboxStealthCrawler()
    await crawler.run()
    crawler.save_csv()
    print("âœ… [Vitabox] ä»»å‹™å®Œæˆ")

async def run_daiken():
    """å°è£å¤§ç ”ç”Ÿé†«çˆ¬èŸ²åŸ·è¡Œé‚è¼¯"""
    print("ğŸš€ [Daiken] ä»»å‹™å•Ÿå‹•...")
    await scrape_daiken_all_products()
    print("âœ… [Daiken] ä»»å‹™å®Œæˆ")

async def run_dietician():
    """å°è£ç‡Ÿé¤Šå¸«è¼•é£Ÿçˆ¬èŸ²åŸ·è¡Œé‚è¼¯"""
    print("ğŸš€ [Dietician] ä»»å‹™å•Ÿå‹• (å« AI åˆ†æ)...")
    await scrape_dietician_all_products()
    print("âœ… [Dietician] ä»»å‹™å®Œæˆ")

async def main():
    start_time = time.time()
    print("="*50)
    print("ğŸ¤– VITAGUIDE D2C è¯åˆçˆ¬èŸ²ä»»å‹™é–‹å§‹")
    print("="*50)

    # ç¢ºä¿è³‡æ–™å¤¾å­˜åœ¨
    os.makedirs("data", exist_ok=True)

    # å¹³è¡ŒåŸ·è¡Œæ‰€æœ‰çˆ¬èŸ²
    # æ³¨æ„ï¼šé€™æœƒåŒæ™‚é–‹å•Ÿå¤šå€‹ç€è¦½å™¨è¦–çª—ï¼Œè«‹ç¢ºä¿ç³»çµ±è³‡æºå……è¶³
    await asyncio.gather(
        run_daiken(),
        run_vitabox(),
        run_dietician()
    )

    end_time = time.time()
    duration = end_time - start_time
    
    print("\n" + "="*50)
    print(f"ğŸ‰ æ‰€æœ‰ D2C çˆ¬èŸ²ä»»å‹™å·²å®Œæˆï¼ç¸½è€—æ™‚: {duration:.2f} ç§’")
    print("="*50)
    
    # ç°¡å–®é©—è­‰æª”æ¡ˆç”¢å‡º
    expected_files = [
        "data/d2c_daiken_all_products.csv",
        "data/d2c_vitabox.csv",
        "data/d2c_dietician_products.csv"
    ]
    for f in expected_files:
        status = "âœ… å­˜åœ¨" if os.path.exists(f) else "âŒ ç¼ºå¤±"
        print(f"æª”æ¡ˆæª¢æŸ¥ [{f}]: {status}")

if __name__ == "__main__":
    asyncio.run(main())